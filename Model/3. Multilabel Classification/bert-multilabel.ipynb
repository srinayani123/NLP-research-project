{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\n\ntrain = pd.read_csv('/kaggle/input/unbalanced/trainu.csv')\ntest = pd.read_csv('/kaggle/input/unbalanced/testu.csv')","metadata":{"id":"8INzLonzDqXP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ec02153e-e4ef-4a87-c93d-f27a40d08de7","execution":{"iopub.status.busy":"2023-04-16T22:00:36.186985Z","iopub.execute_input":"2023-04-16T22:00:36.187567Z","iopub.status.idle":"2023-04-16T22:00:54.923558Z","shell.execute_reply.started":"2023-04-16T22:00:36.187524Z","shell.execute_reply":"2023-04-16T22:00:54.922412Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Balancing the dataset by undersampling from the majority class\ndf_train_1 = train[train['Target']== 1]\ndf_train_0 = train[train['Target']== 0]\ndf_train_0_downsampled = df_train_0.sample(df_train_1.shape[0])\ndf_balanced = pd.concat([df_train_0_downsampled, df_train_1])\ndf_balanced['Target'].value_counts()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"Jo75EdIfQi7M","outputId":"957e2a7f-7ddd-42d8-f048-48ee0ca2054f","execution":{"iopub.status.busy":"2023-04-16T22:02:26.585910Z","iopub.execute_input":"2023-04-16T22:02:26.586691Z","iopub.status.idle":"2023-04-16T22:02:26.715853Z","shell.execute_reply.started":"2023-04-16T22:02:26.586654Z","shell.execute_reply":"2023-04-16T22:02:26.714721Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"0    50715\n1    50715\nName: Target, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"data = df_balanced[['comment_text','severe_toxicity', 'obscene', 'sexual_explicit', 'identity_attack','insult','threat','other','Target']]\ndata.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-04-16T22:19:35.302331Z","iopub.execute_input":"2023-04-16T22:19:35.303023Z","iopub.status.idle":"2023-04-16T22:19:35.325850Z","shell.execute_reply.started":"2023-04-16T22:19:35.302984Z","shell.execute_reply":"2023-04-16T22:19:35.324633Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                             comment_text  severe_toxicity  \\\n32264   Hebrew and Abrahamic males took many wives (it...                0   \n206701             What fake news? What do you even mean?                0   \n199181  \"St. Paul never proposed that two believers go...                0   \n278882  Good luck. Just let Alberta change it and be d...                0   \n293622  (Part two of four)  So, if election night prov...                0   \n\n        obscene  sexual_explicit  identity_attack  insult  threat  other  \\\n32264         0                0                0       0       0      1   \n206701        0                0                0       0       0      1   \n199181        0                0                0       0       0      1   \n278882        0                0                0       0       0      1   \n293622        0                0                0       0       0      1   \n\n        Target  \n32264        0  \n206701       0  \n199181       0  \n278882       0  \n293622       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>severe_toxicity</th>\n      <th>obscene</th>\n      <th>sexual_explicit</th>\n      <th>identity_attack</th>\n      <th>insult</th>\n      <th>threat</th>\n      <th>other</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32264</th>\n      <td>Hebrew and Abrahamic males took many wives (it...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>206701</th>\n      <td>What fake news? What do you even mean?</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>199181</th>\n      <td>\"St. Paul never proposed that two believers go...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>278882</th>\n      <td>Good luck. Just let Alberta change it and be d...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>293622</th>\n      <td>(Part two of four)  So, if election night prov...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sentences=data['comment_text']\nlabels=data['Target']\nlen(sentences),len(labels)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"97F424OOQ-0F","outputId":"a9e38a30-d045-44c6-eead-68c08a5c0660","execution":{"iopub.status.busy":"2023-04-16T22:19:39.196158Z","iopub.execute_input":"2023-04-16T22:19:39.196541Z","iopub.status.idle":"2023-04-16T22:19:39.205902Z","shell.execute_reply.started":"2023-04-16T22:19:39.196505Z","shell.execute_reply":"2023-04-16T22:19:39.204665Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(101430, 101430)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eoqa58Yovo-S","outputId":"6c026990-819a-4cd0-cfb6-d45e3314e71f","execution":{"iopub.status.busy":"2023-04-16T22:25:12.175364Z","iopub.execute_input":"2023-04-16T22:25:12.176468Z","iopub.status.idle":"2023-04-16T22:25:31.055223Z","shell.execute_reply.started":"2023-04-16T22:25:12.176415Z","shell.execute_reply":"2023-04-16T22:25:31.051433Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b30f32b2730402c9001edb447148715"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9d35728357d48f4a12f16cf242050ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"899c9c5b9b0a4147928fe840eac0809d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tf_model.h5:   0%|          | 0.00/536M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9c23823210c4a90b755f2337bc578f1"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n\nSome layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"#loop through the input sentences as part of the dataset and find the input ids and attention masks by storing it in an array\ninput_ids=[]\nattention_masks=[]\n\nfor sent in sentences:\n    bert_inp=bert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =64,pad_to_max_length = True,return_attention_mask = True)\n    input_ids.append(bert_inp['input_ids'])\n    attention_masks.append(bert_inp['attention_mask'])\n\ninput_ids=np.asarray(input_ids)\nattention_masks=np.array(attention_masks)\nlabels=np.array(labels)\n\nlen(input_ids),len(attention_masks),len(labels)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JlBOeC1tEL8A","outputId":"0fd9ecae-7523-4905-dd80-8f5813e88ee9","execution":{"iopub.status.busy":"2023-04-16T22:46:00.830502Z","iopub.execute_input":"2023-04-16T22:46:00.831193Z","iopub.status.idle":"2023-04-16T22:49:16.697817Z","shell.execute_reply.started":"2023-04-16T22:46:00.831156Z","shell.execute_reply":"2023-04-16T22:49:16.696805Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2352: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(101430, 101430, 101430)"},"metadata":{}}]},{"cell_type":"code","source":"#split the dataset into train(80%) and validation(20%)\nfrom sklearn.model_selection import train_test_split\ntrain_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.2)\n\nprint('Train inp shape {} Val input shape {}\\nTrain label shape {} Val label shape {}\\nTrain attention mask shape {} Val attention mask shape {}'.format(train_inp.shape,val_inp.shape,train_label.shape,val_label.shape,train_mask.shape,val_mask.shape))","metadata":{"execution":{"iopub.status.busy":"2023-04-16T22:49:26.505161Z","iopub.execute_input":"2023-04-16T22:49:26.505831Z","iopub.status.idle":"2023-04-16T22:49:26.559949Z","shell.execute_reply.started":"2023-04-16T22:49:26.505795Z","shell.execute_reply":"2023-04-16T22:49:26.558724Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Train inp shape (81144, 64) Val input shape (20286, 64)\nTrain label shape (81144,) Val label shape (20286,)\nTrain attention mask shape (81144, 64) Val attention mask shape (20286, 64)\n","output_type":"stream"}]},{"cell_type":"code","source":"# pickle the input ids and labels along with the labels of the dataset\nimport pickle\nprint('Preparing the pickle file.....')\n\npickle_inp_path='/kaggle/working/bert_inp.pkl'\npickle_mask_path='/kaggle/working/bert_mask.pkl'\npickle_label_path='/kaggle/working/bert_label.pkl'\n\npickle.dump((input_ids),open(pickle_inp_path,'wb'))\npickle.dump((attention_masks),open(pickle_mask_path,'wb'))\npickle.dump((labels),open(pickle_label_path,'wb'))\n\n\nprint('Pickle files saved as ',pickle_inp_path,pickle_mask_path,pickle_label_path)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"irNCKUYKIdAj","outputId":"dc74a609-78c7-41c1-ad90-a61b0af63dff","execution":{"iopub.status.busy":"2023-04-16T22:49:37.390884Z","iopub.execute_input":"2023-04-16T22:49:37.391643Z","iopub.status.idle":"2023-04-16T22:49:37.567697Z","shell.execute_reply.started":"2023-04-16T22:49:37.391589Z","shell.execute_reply":"2023-04-16T22:49:37.566474Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Preparing the pickle file.....\nPickle files saved as  /kaggle/working/bert_inp.pkl /kaggle/working/bert_mask.pkl /kaggle/working/bert_label.pkl\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Loading the saved pickle files..')\n\npickle_inp_path='/kaggle/input/pickled-files/bert_inp.pkl'\npickle_mask_path='/kaggle/input/pickled-files/bert_mask.pkl'\npickle_label_path='/kaggle/input/pickled-files/bert_label.pkl'\n\ninput_ids=pickle.load(open(pickle_inp_path, 'rb'))\nattention_masks=pickle.load(open(pickle_mask_path, 'rb'))\nlabels=pickle.load(open(pickle_label_path, 'rb'))\n\nprint('Input shape {} Attention mask shape {} Input label shape {}'.format(input_ids.shape,attention_masks.shape,labels.shape))","metadata":{"execution":{"iopub.status.busy":"2023-04-16T22:49:40.310196Z","iopub.execute_input":"2023-04-16T22:49:40.310700Z","iopub.status.idle":"2023-04-16T22:49:40.340621Z","shell.execute_reply.started":"2023-04-16T22:49:40.310663Z","shell.execute_reply":"2023-04-16T22:49:40.339062Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Loading the saved pickle files..\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/1231795136.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpickle_label_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/kaggle/input/pickled-files/bert_label.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_inp_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mattention_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_mask_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_label_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/pickled-files/bert_inp.pkl'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/pickled-files/bert_inp.pkl'","output_type":"error"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.2)\n\nprint('Train inp shape {} Val input shape {}\\nTrain label shape {} Val label shape {}\\nTrain attention mask shape {} Val attention mask shape {}'.format(train_inp.shape,val_inp.shape,train_label.shape,val_label.shape,train_mask.shape,val_mask.shape))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2J4mjMxoKI6q","outputId":"9d5a5162-6f60-4b5d-9dfd-13a5b04c1601","execution":{"iopub.status.busy":"2023-04-16T20:17:37.149654Z","iopub.execute_input":"2023-04-16T20:17:37.150139Z","iopub.status.idle":"2023-04-16T20:17:37.241848Z","shell.execute_reply.started":"2023-04-16T20:17:37.150097Z","shell.execute_reply":"2023-04-16T20:17:37.240747Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Train inp shape (81144, 64) Val input shape (20286, 64)\nTrain label shape (81144,) Val label shape (20286,)\nTrain attention mask shape (81144, 64) Val attention mask shape (20286, 64)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TFBertModel,BertConfig, BertTokenizerFast\n\nconfig = BertConfig.from_pretrained('bert-base-uncased')\nconfig.output_hidden_states = False\n\ntokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = 'bert-base-uncased', config = config)\n# Load the Transformers BERT model\ntransformer_model = TFBertModel.from_pretrained('bert-base-uncased', config = config)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2FXy8vEaKnUK","outputId":"a7e7db00-470e-4036-8484-7b7912fc64a1","execution":{"iopub.status.busy":"2023-04-16T23:03:57.372188Z","iopub.execute_input":"2023-04-16T23:03:57.372933Z","iopub.status.idle":"2023-04-16T23:03:58.909023Z","shell.execute_reply.started":"2023-04-16T23:03:57.372889Z","shell.execute_reply":"2023-04-16T23:03:58.907883Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dropout, Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.initializers import TruncatedNormal\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.metrics import CategoricalAccuracy\nfrom tensorflow.keras.utils import to_categorical\n\n# Load the MainLayer\nbert = transformer_model.layers[0]\n# Build your model input\ninput_ids = Input(shape=(100,), name='input_ids', dtype='int32')\ninputs = {'input_ids': input_ids}\n# Load the Transformers BERT model as a layer in a Keras model\nbert_model = bert(inputs)[1]\ndropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\npooled_output = dropout(bert_model, training=False)\n# Then build your model output\nsevere_toxicity = Dense(units=len(data.severe_toxicity.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='severe_toxicity')(pooled_output)\nobscene = Dense(units=len(data.obscene.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='obscene')(pooled_output)\nsexual_explicit = Dense(units=len(data.sexual_explicit.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='sexual_explicit')(pooled_output)\nidentity_attack = Dense(units=len(data.identity_attack.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='identity_attack')(pooled_output)\ninsult = Dense(units=len(data.insult.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='insult')(pooled_output)\nthreat = Dense(units=len(data.threat.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='threat')(pooled_output)\noutputs = {'severe_toxicity': severe_toxicity, 'obscene': obscene,'sexual_explicit': sexual_explicit, 'identity_attack':identity_attack,'insult':insult, 'threat':threat}\n# And combine it all in a model object\nmodel = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n# Take a look at the model\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-16T23:25:09.948000Z","iopub.execute_input":"2023-04-16T23:25:09.948706Z","iopub.status.idle":"2023-04-16T23:25:12.089807Z","shell.execute_reply.started":"2023-04-16T23:25:09.948668Z","shell.execute_reply":"2023-04-16T23:25:12.088971Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Model: \"BERT_MultiLabel_MultiClass\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_ids (InputLayer)         [(None, 100)]        0           []                               \n                                                                                                  \n bert (TFBertMainLayer)         TFBaseModelOutputWi  109482240   ['input_ids[0][0]']              \n                                thPoolingAndCrossAt                                               \n                                tentions(last_hidde                                               \n                                n_state=(None, 100,                                               \n                                 768),                                                            \n                                 pooler_output=(Non                                               \n                                e, 768),                                                          \n                                 past_key_values=No                                               \n                                ne, hidden_states=N                                               \n                                one, attentions=Non                                               \n                                e, cross_attentions                                               \n                                =None)                                                            \n                                                                                                  \n pooled_output (Dropout)        (None, 768)          0           ['bert[1][1]']                   \n                                                                                                  \n identity_attack (Dense)        (None, 2)            1538        ['pooled_output[0][0]']          \n                                                                                                  \n insult (Dense)                 (None, 2)            1538        ['pooled_output[0][0]']          \n                                                                                                  \n obscene (Dense)                (None, 2)            1538        ['pooled_output[0][0]']          \n                                                                                                  \n severe_toxicity (Dense)        (None, 2)            1538        ['pooled_output[0][0]']          \n                                                                                                  \n sexual_explicit (Dense)        (None, 2)            1538        ['pooled_output[0][0]']          \n                                                                                                  \n threat (Dense)                 (None, 2)            1538        ['pooled_output[0][0]']          \n                                                                                                  \n==================================================================================================\nTotal params: 109,491,468\nTrainable params: 109,491,468\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set an optimizer\noptimizer = Adam(\n    learning_rate=5e-05,\n    epsilon=1e-08)\n# Set loss and metrics\nloss = {'severe_toxicity': CategoricalCrossentropy(from_logits = True), 'obscene': CategoricalCrossentropy(from_logits = True), 'sexual_explicit': CategoricalCrossentropy(from_logits = True), 'identity_attack': CategoricalCrossentropy(from_logits = True), 'insult': CategoricalCrossentropy(from_logits = True), 'threat': CategoricalCrossentropy(from_logits = True) }\nmetric = {'severe_toxicity': CategoricalAccuracy('accuracy'), 'obscene': CategoricalAccuracy('accuracy'), 'sexual_explicit': CategoricalAccuracy('accuracy'), 'identity_attack': CategoricalAccuracy('accuracy'), 'insult': CategoricalAccuracy('accuracy'), 'threat': CategoricalAccuracy('accuracy')}\n# Compile the model\nmodel.compile(\n    optimizer = optimizer,\n    loss = loss, \n    metrics = metric)\n# Ready output data for the model\ny_severe_toxicity = to_categorical(data['severe_toxicity'])\ny_obscene = to_categorical(data['obscene'])\ny_sexual_explicit = to_categorical(data['sexual_explicit'])\ny_identity_attack = to_categorical(data['identity_attack'])\ny_insult = to_categorical(data['insult'])\ny_threat = to_categorical(data['threat'])\n\n# Tokenize the input (takes some time)\nx = tokenizer(\n    text=data['comment_text'].to_list(),\n    add_special_tokens=True,\n    max_length=100,\n    truncation=True,\n    padding=True, \n    return_tensors='tf',\n    return_token_type_ids = False,\n    return_attention_mask = False,\n    verbose = True)\n# Fit the model\nhistory = model.fit(\n    x={'input_ids': x['input_ids']},\n    y={'severe_toxicity': y_severe_toxicity, 'obscene': y_obscene, 'sexual_explicit': y_sexual_explicit, 'identity_attack': y_identity_attack, 'insult': y_insult, 'threat': y_threat},\n    validation_split=0.2,\n    batch_size=64,\n    epochs=3)","metadata":{"id":"fUGJFaunK0AW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"173dda54-7145-4a8c-ff6d-74eb939871f6","execution":{"iopub.status.busy":"2023-04-16T23:38:26.730267Z","iopub.execute_input":"2023-04-16T23:38:26.730721Z","iopub.status.idle":"2023-04-17T01:02:37.908974Z","shell.execute_reply.started":"2023-04-16T23:38:26.730684Z","shell.execute_reply":"2023-04-17T01:02:37.907765Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Epoch 1/3\n1268/1268 [==============================] - 1704s 1s/step - loss: 0.5700 - identity_attack_loss: 0.1617 - insult_loss: 0.2767 - obscene_loss: 0.0505 - severe_toxicity_loss: 0.0066 - sexual_explicit_loss: 0.0450 - threat_loss: 0.0295 - identity_attack_accuracy: 0.9378 - insult_accuracy: 0.8906 - obscene_accuracy: 0.9879 - severe_toxicity_accuracy: 0.9993 - sexual_explicit_accuracy: 0.9890 - threat_accuracy: 0.9939 - val_loss: 1.0188 - val_identity_attack_loss: 0.3134 - val_insult_loss: 0.4987 - val_obscene_loss: 0.0923 - val_severe_toxicity_loss: 0.0017 - val_sexual_explicit_loss: 0.0642 - val_threat_loss: 0.0484 - val_identity_attack_accuracy: 0.8595 - val_insult_accuracy: 0.7808 - val_obscene_accuracy: 0.9691 - val_severe_toxicity_accuracy: 0.9999 - val_sexual_explicit_accuracy: 0.9756 - val_threat_accuracy: 0.9844\nEpoch 2/3\n1268/1268 [==============================] - 1653s 1s/step - loss: 0.4023 - identity_attack_loss: 0.1243 - insult_loss: 0.2046 - obscene_loss: 0.0310 - severe_toxicity_loss: 6.1393e-04 - sexual_explicit_loss: 0.0255 - threat_loss: 0.0163 - identity_attack_accuracy: 0.9471 - insult_accuracy: 0.9171 - obscene_accuracy: 0.9899 - severe_toxicity_accuracy: 1.0000 - sexual_explicit_accuracy: 0.9913 - threat_accuracy: 0.9954 - val_loss: 1.0783 - val_identity_attack_loss: 0.3479 - val_insult_loss: 0.5357 - val_obscene_loss: 0.0835 - val_severe_toxicity_loss: 0.0021 - val_sexual_explicit_loss: 0.0613 - val_threat_loss: 0.0478 - val_identity_attack_accuracy: 0.8600 - val_insult_accuracy: 0.7805 - val_obscene_accuracy: 0.9733 - val_severe_toxicity_accuracy: 0.9999 - val_sexual_explicit_accuracy: 0.9781 - val_threat_accuracy: 0.9848\nEpoch 3/3\n1268/1268 [==============================] - 1653s 1s/step - loss: 0.3002 - identity_attack_loss: 0.0952 - insult_loss: 0.1520 - obscene_loss: 0.0235 - severe_toxicity_loss: 4.6555e-04 - sexual_explicit_loss: 0.0189 - threat_loss: 0.0102 - identity_attack_accuracy: 0.9605 - insult_accuracy: 0.9388 - obscene_accuracy: 0.9926 - severe_toxicity_accuracy: 0.9999 - sexual_explicit_accuracy: 0.9936 - threat_accuracy: 0.9971 - val_loss: 1.2214 - val_identity_attack_loss: 0.3487 - val_insult_loss: 0.6565 - val_obscene_loss: 0.0923 - val_severe_toxicity_loss: 0.0012 - val_sexual_explicit_loss: 0.0686 - val_threat_loss: 0.0540 - val_identity_attack_accuracy: 0.8540 - val_insult_accuracy: 0.7689 - val_obscene_accuracy: 0.9720 - val_severe_toxicity_accuracy: 0.9999 - val_sexual_explicit_accuracy: 0.9777 - val_threat_accuracy: 0.9849\n","output_type":"stream"}]},{"cell_type":"code","source":"test_y_severe_toxicity = to_categorical(test['severe_toxicity'])\ntest_y_obscene = to_categorical(test['obscene'])\ntest_y_sexual_explicit = to_categorical(test['sexual_explicit'])\ntest_y_identity_attack = to_categorical(test['identity_attack'])\ntest_y_insult = to_categorical(test['insult'])\ntest_y_threat = to_categorical(test['threat'])\ntest_x = tokenizer(\n    text=test['comment_text'].to_list(),\n    add_special_tokens=True,\n    max_length=100,\n    truncation=True,\n    padding=True, \n    return_tensors='tf',\n    return_token_type_ids = False,\n    return_attention_mask = False,\n    verbose = True)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zyz1HKX9uOrC","outputId":"76e1835a-65e7-44ec-bd8c-0c624068e97e","execution":{"iopub.status.busy":"2023-04-17T01:25:43.065625Z","iopub.execute_input":"2023-04-17T01:25:43.066336Z","iopub.status.idle":"2023-04-17T01:26:10.518794Z","shell.execute_reply.started":"2023-04-17T01:25:43.066299Z","shell.execute_reply":"2023-04-17T01:26:10.517732Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Run evaluation\nmodel_eval = model.evaluate(\n    x={'input_ids': test_x['input_ids']},\n    y={'severe_toxicity': test_y_severe_toxicity, 'obscene': test_y_obscene, 'sexual_explicit': test_y_sexual_explicit, 'identity_attack': test_y_identity_attack, 'insult': test_y_insult, 'threat': test_y_threat},\n)\n\nprint(\"Accuracy: {:.2f}%\".format(model_eval[1] * 100))\nprint(\"Precision: {:.2f}%\".format(model_eval[2] * 100))\nprint(\"Recall: {:.2f}%\".format(model_eval[3] * 100))\nprint(\"F1 score: {:.2f}%\".format(2 * (model_eval[2] * model_eval[3]) / (model_eval[2] + model_eval[3]) * 100))","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:26:53.366817Z","iopub.execute_input":"2023-04-17T01:26:53.367204Z","iopub.status.idle":"2023-04-17T01:42:15.392841Z","shell.execute_reply.started":"2023-04-17T01:26:53.367171Z","shell.execute_reply":"2023-04-17T01:42:15.391698Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"4190/4190 [==============================] - 900s 215ms/step - loss: 0.3100 - identity_attack_loss: 0.0944 - insult_loss: 0.1708 - obscene_loss: 0.0164 - severe_toxicity_loss: 2.5641e-04 - sexual_explicit_loss: 0.0172 - threat_loss: 0.0110 - identity_attack_accuracy: 0.9612 - insult_accuracy: 0.9402 - obscene_accuracy: 0.9948 - severe_toxicity_accuracy: 1.0000 - sexual_explicit_accuracy: 0.9941 - threat_accuracy: 0.9970\nAccuracy: 9.44%\nPrecision: 17.08%\nRecall: 1.64%\nF1 score: 3.00%\n","output_type":"stream"}]},{"cell_type":"code","source":"print(model_eval)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:42:40.531758Z","iopub.execute_input":"2023-04-17T01:42:40.532456Z","iopub.status.idle":"2023-04-17T01:42:40.537299Z","shell.execute_reply.started":"2023-04-17T01:42:40.532422Z","shell.execute_reply":"2023-04-17T01:42:40.536289Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"[0.3100249171257019, 0.09441576898097992, 0.17075058817863464, 0.016420559957623482, 0.00025641440879553556, 0.01722324825823307, 0.010958373546600342, 0.9612177014350891, 0.9402413964271545, 0.9947633743286133, 0.9999776482582092, 0.9940770864486694, 0.9969714283943176]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_input_ids=[]\ntest_attention_masks=[]\ntest_bert_inp=[]\n\nfor sent in test_sentences:\n    bert_inp=bert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =64,pad_to_max_length = True,return_attention_mask = True)\n    test_bert_inp.append(bert_inp)\n    test_input_ids.append(bert_inp['input_ids'])\n    test_attention_masks.append(bert_inp['attention_mask'])\n\ntest_input_ids=np.asarray(test_input_ids)\ntest_attention_masks=np.array(test_attention_masks)\ntest_labels=np.array(test_labels)\n\nlen(test_input_ids),len(test_attention_masks),len(test_labels)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"17kOoYx_I4dr","outputId":"5dacdcb3-92de-49dd-a277-e5481cc777cd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = bert_model.predict([test_input_ids, test_attention_masks])\ntest_preds1 = np.argmax(test_preds, axis=-1)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dNXXFiQRxvhc","outputId":"70c666c5-20b3-4afc-d252-4a04bbf18ecc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds[0]\n\nprobs = tf.nn.softmax(test_preds[0])\nprint(probs)\ntest_preds1 = np.argmax(test_preds[0], axis=-1)\nprint(len(test_preds1))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IgFU9UBm8b7e","outputId":"60c34233-29d4-4e69-f23a-b866add3e316"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_preds1)\nfrom sklearn.metrics import accuracy_score\ntest_acc = accuracy_score(test_labels, test_preds1)\nprint('Test accuracy:', test_acc)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0TY4MIXj6Qmz","outputId":"96cd0b9a-d52c-41a5-b250-892e67f73bc0"},"execution_count":null,"outputs":[]}]}